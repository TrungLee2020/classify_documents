import requests
import json
import logging
from typing import Dict, List

# Setup logging
logging.basicConfig(level=logging.INFO)

class Qwen3Client:
    def __init__(self, base_url: str = "http://localhost:8080"):
        self.base_url = base_url
        self.headers = {"Content-Type": "application/json"}
    
    def generate_text(self, prompt: str, max_tokens: int = 512, temperature: float = 0.1) -> str:
        """G·ªçi API c·ªßa llama-server v·ªõi disable thinking"""
        
        # Disable thinking mode
        prompt = "/no_think\n" + prompt
        
        payload = {
            "prompt": prompt,
            "n_predict": max_tokens,
            "temperature": temperature,
            "stop": ["</s>", "[/INST]"],
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/completion",
                headers=self.headers,
                data=json.dumps(payload),
                timeout=100
            )
            response.raise_for_status()
            result = response.json()
            return result.get("content", "").strip()
        except Exception as e:
            logging.error(f"Error calling Qwen3 API: {e}")
            return ""

class DocumentProcessor:
    def __init__(self, qwen_client: Qwen3Client):
        self.qwen_client = qwen_client
    
    def summarize_text(self, text: str) -> str:
        """T√≥m t·∫Øt vƒÉn b·∫£n s·ª≠ d·ª•ng Qwen3"""
        if len(text) < 100:
            return text
        
        # C·∫Øt text n·∫øu qu√° d√†i
        if len(text) > 1500:
            text = text[:1500] + "..."
        
        prompt = f"""H√£y t√≥m t·∫Øt n·ªôi dung vƒÉn b·∫£n sau th√†nh 2-3 c√¢u ng·∫Øn g·ªçn, t·∫≠p trung v√†o th√¥ng tin ch√≠nh:

        VƒÉn b·∫£n:
        {text}

        T√≥m t·∫Øt:"""
        
        summary = self.qwen_client.generate_text(prompt, max_tokens=200, temperature=0.1)
        
        return summary if summary else text[:300]

class DocumentClassifier:
    def __init__(self, qwen_client: Qwen3Client):
        self.qwen_client = qwen_client
        self.categories = {
            0: "Th√¥ng b√°o",
            1: "T√†i ch√≠nh"
        }
    
    def classify_document(self, text: str) -> Dict:
        """Ph√¢n lo·∫°i vƒÉn b·∫£n d·ª±a tr√™n n·ªôi dung"""
        
        prompt = f"""Ph√¢n lo·∫°i vƒÉn b·∫£n sau thu·ªôc lo·∫°i n√†o:
- Lo·∫°i 0: Th√¥ng b√°o (th√¥ng b√°o n·ªôi b·ªô, c√¥ng vƒÉn, h∆∞·ªõng d·∫´n, quy ƒë·ªãnh, th√¥ng b√°o s·ª± ki·ªán)
- Lo·∫°i 1: T√†i ch√≠nh (b√°o c√°o t√†i ch√≠nh, doanh thu, l·ª£i nhu·∫≠n, ƒë·∫ßu t∆∞, thu·∫ø, ng√¢n h√†ng, b·∫£o hi·ªÉm)

N·ªôi dung c·∫ßn ph√¢n lo·∫°i:
{text}

H√£y tr·∫£ l·ªùi theo format ch√≠nh x√°c:
Lo·∫°i: [0 ho·∫∑c 1]
ƒê·ªô tin c·∫≠y: [s·ªë t·ª´ 0.0 ƒë·∫øn 1.0]
L√Ω do: [gi·∫£i th√≠ch ng·∫Øn g·ªçn]"""

        response = self.qwen_client.generate_text(prompt, max_tokens=150, temperature=0.0)
        
        # Parse response
        category, confidence, reason = self._parse_classification_response(response)
        
        return {
            "category": self.categories.get(category, "Kh√¥ng x√°c ƒë·ªãnh"),
            "category_id": category,
            "confidence": confidence,
            "reason": reason,
            "raw_response": response
        }
    
    def _parse_classification_response(self, response: str) -> tuple:
        """Parse response t·ª´ Qwen3"""
        try:
            lines = response.strip().split('\n')
            category = 0
            confidence = 0.5
            reason = "Kh√¥ng c√≥ l√Ω do"
            
            for line in lines:
                line = line.strip()
                if line.startswith("Lo·∫°i:"):
                    try:
                        category = int(line.split(":")[1].strip())
                    except:
                        category = 0
                elif line.startswith("ƒê·ªô tin c·∫≠y:"):
                    try:
                        confidence = float(line.split(":")[1].strip())
                    except:
                        confidence = 0.5
                elif line.startswith("L√Ω do:"):
                    reason = line.split(":", 1)[1].strip()
            
            return category, confidence, reason
            
        except Exception as e:
            logging.error(f"Error parsing response: {e}")
            return 0, 0.5, "L·ªói ph√¢n t√≠ch"

def test_classification_with_sample_data():
    """Test ph√¢n lo·∫°i v·ªõi d·ªØ li·ªáu m·∫´u"""
    
    # D·ªØ li·ªáu m·∫´u - Th√¥ng b√°o (Label: 0)
    thong_bao_samples = [
        "K√≠nh g·ª≠i to√†n th·ªÉ nh√¢n vi√™n ph√≤ng Kinh doanh, Tr∆∞·ªüng ph√≤ng y√™u c·∫ßu m·ªôt cu·ªôc h·ªçp kh·∫©n c·∫•p v√†o l√∫c 14h00 chi·ªÅu nay, ng√†y [Ng√†y/Th√°ng/NƒÉm], t·∫°i ph√≤ng h·ªçp s·ªë 2. N·ªôi dung: Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ ph√°t sinh t·ª´ h·ª£p ƒë·ªìng kh√°ch h√†ng X. Y√™u c·∫ßu t·∫•t c·∫£ c√°c th√†nh vi√™n c√≥ m·∫∑t ƒë·∫ßy ƒë·ªß v√† ƒë√∫ng gi·ªù.",
        
        "C√¥ng ty C·ªï ph·∫ßn ABC tr√¢n tr·ªçng th√¥ng b√°o ƒë·∫øn to√†n th·ªÉ Qu√Ω ƒê·ªëi t√°c v√† Kh√°ch h√†ng l·ªãch ngh·ªâ l·ªÖ Gi·ªó T·ªï H√πng V∆∞∆°ng (M√πng 10/3 √Çm l·ªãch) nh∆∞ sau: Th·ªùi gian ngh·ªâ: Th·ª© NƒÉm, ng√†y [Ng√†y/Th√°ng/NƒÉm]. C√¥ng ty s·∫Ω ho·∫°t ƒë·ªông tr·ªü l·∫°i b√¨nh th∆∞·ªùng v√†o Th·ª© S√°u, ng√†y [Ng√†y/Th√°ng/NƒÉm]. K√≠nh ch√∫c Qu√Ω v·ªã m·ªôt k·ª≥ ngh·ªâ l·ªÖ vui v·∫ª!",
        
        "K√≠nh g·ª≠i Qu√Ω Kh√°ch h√†ng, k·ªÉ t·ª´ ng√†y [Ng√†y/Th√°ng/NƒÉm], VƒÉn ph√≤ng Giao d·ªãch c·ªßa C√¥ng ty TNHH XYZ s·∫Ω ch√≠nh th·ª©c chuy·ªÉn v·ªÅ ƒë·ªãa ƒëi·ªÉm m·ªõi t·∫°i: T·∫ßng 5, T√≤a nh√† Central Park, S·ªë 123 ƒê∆∞·ªùng DEF, Qu·∫≠n GHI, Th√†nh ph·ªë JKL. M·ªçi th√¥ng tin li√™n h·ªá kh√°c kh√¥ng thay ƒë·ªïi. R·∫•t mong ti·∫øp t·ª•c nh·∫≠n ƒë∆∞·ª£c s·ª± ·ªßng h·ªô c·ªßa Qu√Ω v·ªã.",
        
        "C√¥ng ty Ph√°t tri·ªÉn C√¥ng ngh·ªá Alpha ƒëang c√≥ nhu c·∫ßu tuy·ªÉn d·ª•ng 02 v·ªã tr√≠ L·∫≠p tr√¨nh vi√™n Java v·ªõi kinh nghi·ªám t·ª´ 2 nƒÉm tr·ªü l√™n. ·ª®ng vi√™n quan t√¢m vui l√≤ng g·ª≠i CV v·ªÅ ƒë·ªãa ch·ªâ email: tuyendung@alpha-tech.vn tr∆∞·ªõc ng√†y [Ng√†y/Th√°ng/NƒÉm]. Chi ti·∫øt m√¥ t·∫£ c√¥ng vi·ªác vui l√≤ng xem t·∫°i website c·ªßa c√¥ng ty.",
        
        "Th√¥ng b√°o v·ªÅ vi·ªác b·∫£o tr√¨ h·ªá th·ªëng m√°y ch·ªß: ƒê·ªÉ n√¢ng cao ch·∫•t l∆∞·ª£ng d·ªãch v·ª•, ch√∫ng t√¥i s·∫Ω ti·∫øn h√†nh b·∫£o tr√¨ h·ªá th·ªëng t·ª´ 23h00 ng√†y [Ng√†y/Th√°ng/NƒÉm] ƒë·∫øn 05h00 ng√†y [Ng√†y/Th√°ng/NƒÉm]. Trong th·ªùi gian n√†y, c√°c d·ªãch v·ª• tr·ª±c tuy·∫øn c√≥ th·ªÉ b·ªã gi√°n ƒëo·∫°n. Mong Qu√Ω kh√°ch h√†ng th√¥ng c·∫£m cho s·ª± b·∫•t ti·ªán n√†y."
    ]
    
    # D·ªØ li·ªáu m·∫´u - T√†i ch√≠nh (Label: 1)
    tai_chinh_samples = [
        "D·ª± √°n ƒë·∫ßu t∆∞ v√†o nh√† m√°y s·∫£n xu·∫•t Y sau m·ªôt nƒÉm v·∫≠n h√†nh ƒë√£ cho th·∫•y t·ª∑ su·∫•t l·ª£i nhu·∫≠n tr√™n v·ªën ch·ªß s·ªü h·ªØu (ROE) ƒë·∫°t 18%, v∆∞·ª£t 3% so v·ªõi m·ª•c ti√™u ban ƒë·∫ßu. D√≤ng ti·ªÅn thu·∫ßn t·ª´ ho·∫°t ƒë·ªông kinh doanh d∆∞∆°ng ·ªïn ƒë·ªãnh, cho th·∫•y ti·ªÅm nƒÉng tƒÉng tr∆∞·ªüng b·ªÅn v·ªØng v√† kh·∫£ nƒÉng thu h·ªìi v·ªën nhanh.",
        
        "K·∫øt th√∫c Qu√Ω III/2023, C√¥ng ty C·ªï ph·∫ßn Z ghi nh·∫≠n doanh thu thu·∫ßn ƒë·∫°t 250 t·ª∑ ƒë·ªìng, tƒÉng 15% so v·ªõi c√πng k·ª≥ nƒÉm ngo√°i. L·ª£i nhu·∫≠n sau thu·∫ø ƒë·∫°t 25 t·ª∑ ƒë·ªìng, ho√†n th√†nh 110% k·∫ø ho·∫°ch qu√Ω. K·∫øt qu·∫£ n√†y ch·ªß y·∫øu ƒë·∫øn t·ª´ s·ª± tƒÉng tr∆∞·ªüng m·∫°nh m·∫Ω c·ªßa m·∫£ng s·∫£n ph·∫©m ch·ªß l·ª±c v√† ki·ªÉm so√°t chi ph√≠ hi·ªáu qu·∫£.",
        
        "ƒê·ªÉ gi·∫£m thi·ªÉu r·ªßi ro v√† t·ªëi ∆∞u h√≥a l·ª£i nhu·∫≠n trong b·ªëi c·∫£nh th·ªã tr∆∞·ªùng bi·∫øn ƒë·ªông, nh√† ƒë·∫ßu t∆∞ n√™n c√¢n nh·∫Øc ƒëa d·∫°ng h√≥a danh m·ª•c ƒë·∫ßu t∆∞. Vi·ªác ph√¢n b·ªï v·ªën v√†o c√°c lo·∫°i t√†i s·∫£n kh√°c nhau nh∆∞ c·ªï phi·∫øu, tr√°i phi·∫øu, b·∫•t ƒë·ªông s·∫£n v√† v√†ng c√≥ th·ªÉ gi√∫p c√¢n b·∫±ng r·ªßi ro v√† n·∫Øm b·∫Øt c∆° h·ªôi tƒÉng tr∆∞·ªüng t·ª´ nhi·ªÅu ngu·ªìn.",
        
        "Theo Ngh·ªã ƒë·ªãnh 123/2023/Nƒê-CP, k·ªÉ t·ª´ ng√†y 01/01/2024, m·ªôt s·ªë quy ƒë·ªãnh v·ªÅ thu·∫ø thu nh·∫≠p doanh nghi·ªáp s·∫Ω ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh, bao g·ªìm vi·ªác gi·∫£m thu·∫ø su·∫•t cho doanh nghi·ªáp nh·ªè v√† v·ª´a. C√°c doanh nghi·ªáp c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ƒë·ªÉ ƒë·∫£m b·∫£o tu√¢n th·ªß v√† t·∫≠n d·ª•ng c√°c ∆∞u ƒë√£i (n·∫øu c√≥).",
        
        "Bi·∫øn ƒë·ªông t·ª∑ gi√° USD/VND trong th√°ng qua ch·ªß y·∫øu do t√°c ƒë·ªông t·ª´ ch√≠nh s√°ch ti·ªÅn t·ªá c·ªßa C·ª•c D·ª± tr·ªØ Li√™n bang M·ªπ (FED) v√† d√≤ng v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i. C√°c doanh nghi·ªáp xu·∫•t nh·∫≠p kh·∫©u c·∫ßn theo d√µi s√°t di·ªÖn bi·∫øn t·ª∑ gi√° ƒë·ªÉ c√≥ chi·∫øn l∆∞·ª£c ph√≤ng ng·ª´a r·ªßi ro ph√π h·ª£p."
    ]
    
    # Kh·ªüi t·∫°o components
    qwen_client = Qwen3Client("http://localhost:8080")
    processor = DocumentProcessor(qwen_client)
    classifier = DocumentClassifier(qwen_client)
    
    # Test v·ªõi t√≥m t·∫Øt
    def test_with_summarization(samples, expected_label, category_name):
        print(f"\n{'='*60}")
        print(f"TESTING {category_name.upper()} - With Summarization")
        print(f"{'='*60}")
        
        correct = 0
        total = len(samples)
        
        for i, text in enumerate(samples):
            print(f"\n--- Sample {i+1} ---")
            print(f"Original text: {text[:100]}...")
            
            # T√≥m t·∫Øt
            summary = processor.summarize_text(text)
            print(f"Summary: {summary}")
            
            # Ph√¢n lo·∫°i
            result = classifier.classify_document(summary)
            print(f"Predicted: {result['category']} (ID: {result['category_id']})")
            print(f"Confidence: {result['confidence']:.2f}")
            print(f"Reason: {result['reason']}")
            
            if result['category_id'] == expected_label:
                correct += 1
                print("‚úÖ CORRECT")
            else:
                print("‚ùå WRONG")
        
        accuracy = correct / total * 100
        print(f"\n{category_name} Accuracy: {correct}/{total} = {accuracy:.1f}%")
        return accuracy
    
    # Test tr·ª±c ti·∫øp kh√¥ng t√≥m t·∫Øt
    def test_direct_classification(samples, expected_label, category_name):
        print(f"\n{'='*60}")
        print(f"TESTING {category_name.upper()} - Direct Classification")
        print(f"{'='*60}")
        
        correct = 0
        total = len(samples)
        
        for i, text in enumerate(samples):
            print(f"\n--- Sample {i+1} ---")
            print(f"Text: {text[:100]}...")
            
            # Ph√¢n lo·∫°i tr·ª±c ti·∫øp
            result = classifier.classify_document(text)
            print(f"Predicted: {result['category']} (ID: {result['category_id']})")
            print(f"Confidence: {result['confidence']:.2f}")
            print(f"Reason: {result['reason']}")
            
            if result['category_id'] == expected_label:
                correct += 1
                print("‚úÖ CORRECT")
            else:
                print("‚ùå WRONG")
        
        accuracy = correct / total * 100
        print(f"\n{category_name} Accuracy: {correct}/{total} = {accuracy:.1f}%")
        return accuracy
    
    # Ki·ªÉm tra k·∫øt n·ªëi server
    try:
        response = requests.get("http://localhost:8080/health", timeout=5)
        print("‚úÖ Llama-server is running")
    except:
        print("‚ùå Cannot connect to llama-server. Make sure it's running on localhost:8080")
        return
    
    # Ch·∫°y test
    print("üöÄ STARTING CLASSIFICATION TESTS")
    
    # Test v·ªõi t√≥m t·∫Øt
    tb_acc_summ = test_with_summarization(thong_bao_samples, 0, "TH√îNG B√ÅO")
    tc_acc_summ = test_with_summarization(tai_chinh_samples, 1, "T√ÄI CH√çNH")
    
    # Test tr·ª±c ti·∫øp
    tb_acc_direct = test_direct_classification(thong_bao_samples, 0, "TH√îNG B√ÅO")
    tc_acc_direct = test_direct_classification(tai_chinh_samples, 1, "T√ÄI CH√çNH")
    
    # T·ªïng k·∫øt
    print(f"\n{'='*60}")
    print("FINAL RESULTS")
    print(f"{'='*60}")
    print(f"With Summarization:")
    print(f"  - Th√¥ng b√°o: {tb_acc_summ:.1f}%")
    print(f"  - T√†i ch√≠nh: {tc_acc_summ:.1f}%")
    print(f"  - Overall: {(tb_acc_summ + tc_acc_summ)/2:.1f}%")
    
    print(f"\nDirect Classification:")
    print(f"  - Th√¥ng b√°o: {tb_acc_direct:.1f}%")
    print(f"  - T√†i ch√≠nh: {tc_acc_direct:.1f}%")
    print(f"  - Overall: {(tb_acc_direct + tc_acc_direct)/2:.1f}%")

if __name__ == "__main__":
    test_classification_with_sample_data()